{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbUQ_8dUxYlX"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYtyUZMgxYlY",
        "outputId": "cec342b8-841e-40dc-9d0f-335d63ea61a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 202386/202386 [00:17<00:00, 11883.49it/s]\n",
            "100%|██████████| 50937/50937 [00:02<00:00, 20764.11it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_data(gt_path, data_path):\n",
        " with open(data_path) as f:\n",
        "  data = f.read().splitlines()\n",
        "\n",
        " with open(gt_path, \"r\") as f:\n",
        "  labels = f.read().splitlines()\n",
        "\n",
        " df = pd.DataFrame({\"text\": data, \"label\": labels})\n",
        " df = df[df[\"text\"] != \";;;\"]\n",
        " df[\"text\"] = df[\"text\"].apply(lambda x: x.replace(\";;;\", \"\"))\n",
        " df = df[~(df[\"label\"].str.strip()==\"\")]\n",
        " df = df[~df[\"label\"].str.contains(\";\")]\n",
        "\n",
        " df[\"label\"] = df[\"label\"].str.strip()\n",
        "\n",
        " df[\"label\"] = np.where(df[\"label\"] == \"O O\", \"O\", df[\"label\"])\n",
        " return df\n",
        "\n",
        "train = load_data(\"train_gt.csv\", \"train_data.csv\")\n",
        "valid = load_data(\"valid_gt.csv\", \"valid_data.csv\")\n",
        "label_mapping = {'O': 0, 'B-ORG': 1, 'B-MISC': 2, 'B-PER': 3, 'I-PER': 4, 'B-LOC': 5, 'I-ORG': 6, 'I-MISC': 7, 'I-LOC': 8}\n",
        "train['label'] = train['label'].map(label_mapping)\n",
        "valid['label'] = valid['label'].map(label_mapping)\n",
        "ner_pos = preprocessing.LabelEncoder()\n",
        "def rows_to_sentences_and_labels(df):\n",
        "    sentences = []\n",
        "    sentences_labels = []\n",
        "    current_sentence = []\n",
        "    current_labels = []\n",
        "\n",
        "    for index, row in tqdm(df.iterrows(), total = len(df)):\n",
        "        word, label = row['text'], row['label']\n",
        "        current_sentence.append(word.strip())\n",
        "        current_labels.append(label)\n",
        "        if word.strip() == '.':\n",
        "            sentences.append(current_sentence)\n",
        "            sentences_labels.append(current_labels)\n",
        "            current_sentence = []\n",
        "            current_labels = []\n",
        "\n",
        "    return sentences, sentences_labels\n",
        "\n",
        "train_sentences, train_sentences_labels = rows_to_sentences_and_labels(train)\n",
        "valid_sentences, valid_sentences_labels = rows_to_sentences_and_labels(valid)\n",
        "\n",
        "train_sentences_str = [item for sublist in train_sentences for item in sublist]\n",
        "valid_sentences_str = [item for sublist in valid_sentences for item in sublist]\n",
        "train_sentences_labels_str = [item for sublist in train_sentences_labels for item in sublist]\n",
        "valid_sentences_labels_str = [item for sublist in valid_sentences for item in sublist]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TElS0B3KxYla"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNEY3bJ5xYla"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj-sa_dExYlb"
      },
      "source": [
        " MultinomialNB model without tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShLbTgNsxYlb",
        "outputId": "63298427-9abb-433f-9c1e-ce0e8d682c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "161891 20236 20237\n",
            "['Party', 'negotiations', 'on', '.', 'for', 'Previous', 'approves', 'on', 'runs', 'the']\n",
            "Development Set Accuracy: 0.9348685510970548\n",
            "Test Set Accuracy: 0.9358106438701389\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9558    0.9955    0.9752     16822\n",
            "           1     0.8477    0.7021    0.7681       658\n",
            "           2     0.8552    0.7066    0.7738       351\n",
            "           3     0.7778    0.6865    0.7293       673\n",
            "           4     0.6960    0.4460    0.5436       426\n",
            "           5     0.8406    0.7753    0.8066       721\n",
            "           6     0.7406    0.4220    0.5377       372\n",
            "           7     0.5806    0.3186    0.4114       113\n",
            "           8     0.7733    0.5800    0.6629       100\n",
            "\n",
            "    accuracy                         0.9349     20236\n",
            "   macro avg     0.7853    0.6258    0.6898     20236\n",
            "weighted avg     0.9281    0.9349    0.9290     20236\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Split the data into training, development, and test sets\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(train_sentences_str, train_sentences_labels_str, test_size=0.20)\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X_dev, y_dev, test_size=0.50)\n",
        "\n",
        "print(len(X_train), len(X_dev), len(X_test))\n",
        "print(X_train[:10])\n",
        "# Vectorize the data using TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_features = vectorizer.fit_transform(X_train)\n",
        "X_dev_features = vectorizer.transform(X_dev)\n",
        "X_test_features = vectorizer.transform(X_test)\n",
        "\n",
        "# Encode labels using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform([str(label) for label in y_train])\n",
        "y_dev_encoded = label_encoder.transform([str(label) for label in y_dev])\n",
        "y_test_encoded = label_encoder.transform([str(label) for label in y_test])\n",
        "\n",
        "# Train Multinomial Naive Bayes model\n",
        "multinomial_naive_bayes = MultinomialNB(alpha=0.001)\n",
        "multinomial_naive_bayes.fit(X_train_features, y_train_encoded)\n",
        "\n",
        "# Evaluate on the development set\n",
        "dev_predictions = multinomial_naive_bayes.predict(X_dev_features)\n",
        "accuracy_dev = (dev_predictions == y_dev_encoded).mean()\n",
        "print(f\"Development Set Accuracy: {accuracy_dev}\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_predictions = multinomial_naive_bayes.predict(X_test_features)\n",
        "accuracy_test = (test_predictions == y_test_encoded).mean()\n",
        "print(f\"Test Set Accuracy: {accuracy_test}\")\n",
        "\n",
        "y_dev_predictions = multinomial_naive_bayes.predict(X_dev_features)\n",
        "\n",
        "print(classification_report(y_pred=y_dev_predictions, y_true=y_dev, digits=4, zero_division=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMUeEE83xYlb"
      },
      "source": [
        "GridSearchCV model (has not finish)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ppm3tpzoxYlb",
        "outputId": "57b76c98-db11-466f-96df-743b00d2af3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "Best parameters:\n",
            "{'clf__C': 10, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1)}\n",
            "Development Set Accuracy: 0.9240956710812414\n",
            "Test Set Accuracy: 0.9255324405791372\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9430    0.9946    0.9681     16918\n",
            "           1     0.8248    0.6176    0.7063       625\n",
            "           2     0.8459    0.7108    0.7725       332\n",
            "           3     0.8051    0.6230    0.7024       610\n",
            "           4     0.6947    0.3420    0.4584       459\n",
            "           5     0.8558    0.7479    0.7982       722\n",
            "           6     0.6667    0.3427    0.4527       356\n",
            "           7     0.5556    0.3431    0.4242       102\n",
            "           8     0.6761    0.4248    0.5217       113\n",
            "\n",
            "    accuracy                         0.9255     20237\n",
            "   macro avg     0.7631    0.5718    0.6450     20237\n",
            "weighted avg     0.9165    0.9255    0.9168     20237\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define the pipeline with TF-IDF vectorizer and Logistic Regression classifier\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "])\n",
        "\n",
        "# Define the parameters for grid search\n",
        "parameters = {\n",
        "    'tfidf__max_features': [1000, 5000, 10000],\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
        "}\n",
        "\n",
        "# Perform grid search with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found by grid search\n",
        "print(\"Best parameters:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Evaluate on the development set\n",
        "dev_predictions = grid_search.predict(X_dev)\n",
        "accuracy_dev = (dev_predictions == y_dev).mean()\n",
        "print(f\"Development Set Accuracy: {accuracy_dev}\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_predictions = grid_search.predict(X_test)\n",
        "accuracy_test = (test_predictions == y_test).mean()\n",
        "print(f\"Test Set Accuracy: {accuracy_test}\")\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_pred=test_predictions, y_true=y_test, digits=4, zero_division=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz07891oxYlb"
      },
      "source": [
        "MultinomialNB with tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWlKek_FxYlc",
        "outputId": "ada58e0a-f2bb-46a5-c32e-1871409a3481"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "161891 20236 20237\n",
            "['28', 'North', '95', '936.000', 'the', 'shut', 'Tuesday', 'conditions', 'squad', 'political']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Development Set Accuracy: 0.9358568887131844\n",
            "Test Set Accuracy: 0.9310174432969314\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9518    0.9975    0.9741     16787\n",
            "           1     0.8568    0.6748    0.7550       612\n",
            "           2     0.8758    0.7112    0.7850       367\n",
            "           3     0.8049    0.6960    0.7465       658\n",
            "           4     0.7105    0.4789    0.5722       451\n",
            "           5     0.8866    0.8177    0.8508       746\n",
            "           6     0.7977    0.3740    0.5092       369\n",
            "           7     0.6957    0.2500    0.3678       128\n",
            "           8     0.7831    0.5508    0.6468       118\n",
            "\n",
            "    accuracy                         0.9359     20236\n",
            "   macro avg     0.8181    0.6168    0.6897     20236\n",
            "weighted avg     0.9296    0.9359    0.9289     20236\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "    tokens = [lemmatizer.lemmatize(token.lower(), get_wordnet_pos(tag))\n",
        "              for token, tag in tagged_tokens if token not in string.punctuation and token.lower() not in stopwords.words('english')]\n",
        "    return tokens\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return 'a'  # adjective\n",
        "    elif tag.startswith('V'):\n",
        "        return 'v'  # verb\n",
        "    elif tag.startswith('N'):\n",
        "        return 'n'  # noun\n",
        "    elif tag.startswith('R'):\n",
        "        return 'r'  # adverb\n",
        "    else:\n",
        "        return 'n'  # default to noun if POS tag is unknown\n",
        "\n",
        "\n",
        "\n",
        "# Split the data into training, development, and test sets\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(train_sentences_str, train_sentences_labels_str, test_size=0.20)\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X_dev, y_dev, test_size=0.50)\n",
        "\n",
        "print(len(X_train), len(X_dev), len(X_test))\n",
        "print(X_train[:10])\n",
        "# Vectorize the data using TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1, 2))\n",
        "\n",
        "X_train_features = vectorizer.fit_transform(X_train)\n",
        "X_dev_features = vectorizer.transform(X_dev)\n",
        "X_test_features = vectorizer.transform(X_test)\n",
        "\n",
        "# Encode labels using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform([str(label) for label in y_train])\n",
        "y_dev_encoded = label_encoder.transform([str(label) for label in y_dev])\n",
        "y_test_encoded = label_encoder.transform([str(label) for label in y_test])\n",
        "\n",
        "# Train Multinomial Naive Bayes model\n",
        "multinomial_naive_bayes = MultinomialNB(alpha=0.001)\n",
        "multinomial_naive_bayes.fit(X_train_features, y_train_encoded)\n",
        "\n",
        "# Evaluate on the development set\n",
        "dev_predictions = multinomial_naive_bayes.predict(X_dev_features)\n",
        "accuracy_dev = (dev_predictions == y_dev_encoded).mean()\n",
        "print(f\"Development Set Accuracy: {accuracy_dev}\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_predictions = multinomial_naive_bayes.predict(X_test_features)\n",
        "accuracy_test = (test_predictions == y_test_encoded).mean()\n",
        "print(f\"Test Set Accuracy: {accuracy_test}\")\n",
        "\n",
        "y_dev_predictions = multinomial_naive_bayes.predict(X_dev_features)\n",
        "\n",
        "print(classification_report(y_pred=y_dev_predictions, y_true=y_dev, digits=4, zero_division=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc6e6kckxYlc"
      },
      "source": [
        "---\n",
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIDlbywZxYlc",
        "outputId": "07c7ac9a-1459-4ed2-e023-d73ba0460b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "Predictions using Multinomial Naive Bayes:\n",
            "['0' '0' '0' ... '0' '0' '0']\n"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "import pandas as pd\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def save_file(data, predict, file_name):\n",
        "\n",
        "    # Define the label_mapping_reverse dictionary\n",
        "    label_mapping_reverse = {0: 'O', 1: 'B-ORG', 2: 'B-MISC', 3: 'B-PER', 4: 'I-PER', 5: 'B-LOC', 6: 'I-ORG', 7: 'I-MISC', 8: 'I-LOC'}\n",
        "\n",
        "    # Map elements of nb_predicted_labels using label_mapping_reverse\n",
        "    mapped_labels = [label_mapping_reverse[int(label)] for label in predict]\n",
        "\n",
        "    # Combine the text and mapped_labels into a list of strings\n",
        "    combined_data = []\n",
        "    for text, label in zip(data[\"text\"], mapped_labels):\n",
        "        # Check if the text is not empty or just a space\n",
        "        if text.strip():\n",
        "            combined_data.append(f\"{text.strip()} {label}\\n\")\n",
        "        else:\n",
        "            # If the text is empty or just a space, exclude the label\n",
        "            combined_data.append(f\"  {label}\\n\")\n",
        "\n",
        "    # Write the combined data to a CSV file\n",
        "    with open(file_name, \"w\") as f:\n",
        "        f.writelines(combined_data)\n",
        "# Load and preprocess the new data\n",
        "def preprocess_new_data(data):\n",
        "    # Create a DataFrame with the new data\n",
        "    df = pd.DataFrame({\"text\": data})\n",
        "    # Preprocess the text (if needed)\n",
        "    df[\"text\"] = df[\"text\"].apply(lambda x: x.strip())\n",
        "    return df\n",
        "\n",
        "# Load the new data\n",
        "def load_new_data(data_path):\n",
        "    with open(data_path, \"r\") as file:\n",
        "        data = file.readlines()\n",
        "    return data\n",
        "\n",
        "# Load and preprocess the new data\n",
        "new_data = load_new_data(\"test_data.csv\")\n",
        "new_data_df = preprocess_new_data(new_data)\n",
        "\n",
        "# Vectorize the new data using the fitted vectorizer\n",
        "X_new_features = vectorizer.transform(new_data_df[\"text\"])\n",
        "\n",
        "# Predict using Multinomial Naive Bayes\n",
        "nb_predictions = multinomial_naive_bayes.predict(X_new_features)\n",
        "print(nb_predictions)\n",
        "nb_predicted_labels = label_encoder.inverse_transform(nb_predictions)\n",
        "\n",
        "print(\"Predictions using Multinomial Naive Bayes:\")\n",
        "print(nb_predicted_labels)\n",
        "\n",
        "# Save predictions to a file\n",
        "save_file(new_data_df, nb_predicted_labels, 'predict_nb.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
